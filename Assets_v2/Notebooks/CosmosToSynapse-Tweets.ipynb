{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from azure.cosmos import CosmosClient, PartitionKey\n",
        "from pyspark.sql.types import StructType, StructField, LongType, StringType, DateType, TimestampType,FloatType\n",
        "from notebookutils import mssparkutils\n",
        "import family\n",
        "import json\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from datetime import date, timedelta \n",
        "from datetime import datetime as _datetime \n",
        "import numpy as np\n",
        "import datetime, time\n",
        "from dateutil.parser import parse\n",
        "import re,string\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"config\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Cosmos\n",
        "client = CosmosClient(COSMOS_URL, {'masterKey': COSMOS_KEY})\n",
        "database = client.get_database_client(COSMOS_DATABASE_NAME)\n",
        "tweet_container_client = database.get_container_client(container=COSMOS_CONTAINER_NAME)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "last_inserted_ts = 0\n",
        "jdbc_url = \"jdbc:sqlserver://\" + SYNAPSE_WORKSPACE_NAME + \".sql.azuresynapse.net:1433;database=\" + DB_NAME + \";encrypt=true;trustServerCertificate=true;hostNameInCertificate=*.sql.azuresynapse.net;loginTimeout=30;\"\n",
        "jdbcDF = spark.read.format(\"jdbc\").option(\"url\", jdbc_url).option(\"query\", \"SELECT MAX(inserted_to_CosmosDB_ts) AS outp FROM dbo.Tweets\").option(\"user\", SQL_USERNAME).option(\"password\", SQL_PASSWORD).load()\n",
        "try:\n",
        "    last_inserted_ts = jdbcDF.first()[0]\n",
        "except: \n",
        "    last_inserted_ts = 0\n",
        "if not(last_inserted_ts): # if the table is empty get back None\n",
        "    last_inserted_ts = 0\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "now = datetime.datetime.now()\n",
        "then = now - datetime.timedelta(days=2)\n",
        "#span_ms = int(time.mktime(then.timetuple())) # only for testing. Disregard\n",
        "dt_string = now.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "LANGUAGE_CODES={\"All\":\"\",\"Afrikaans\":\"af\",\"Arabic\":\"ar\",\"Assamese\":\"as\",\"Bangla\":\"bn\",\"Bosnian(Latin)\":\"bs\",\"Bulgarian\":\"bg\",\"Cantonese(Traditional)\":\"yue\",\"Catalan\":\"ca\",\"Chinese Simplified\":\"zh-Hans\",\"Chinese Traditional\":\"zh-Hant\",\"Croatian\":\"hr\",\"Czech\":\"cs\",\"Dari\":\"prs\",\"Danish\":\"da\",\"Dutch\":\"nl\",\"English\":\"en\",\"Estonian\":\"et\",\"Fijian\":\"fj\",\"Filipino\":\"fil\",\"Finnish\":\"fi\",\"French\":\"fr\",\"German\":\"de\",\"Greek\":\"el\",\"Gujarati\":\"gu\",\"Haitian Creole\":\"ht\",\"Hebrew\":\"he\",\"Hindi\":\"hi\",\"Hmong Daw\":\"mww\",\"Hungarian\":\"hu\",\"Icelandic\":\"is\",\"Indonesian\":\"id\",\"Irish\":\"ga\",\"Italian\":\"it\",\"Japanese\":\"ja\",\"Kannada\":\"kn\",\"Kazakh\":\"kk\",\"Klingon\":\"tlh-Latn\",\"Klingon(plqaD)\":\"tlh-Piqd\",\"Korean\":\"ko\",\"Kurdish(Central)\":\"ku\",\"Kurdish(Northern)\":\"kmr\",\"Latvian\":\"lv\",\"Lithuanian\":\"lt\",\"Malagasy\":\"mg\",\"Malay\":\"ms\",\"Malayalam\":\"ml\",\"Maltese\":\"mt\",\"Maori\":\"mi\",\"Marathi\":\"mr\",\"Norwegian\":\"nb\",\"Odia\":\"or\",\"Pashto\":\"ps\",\"Persian\":\"fa\",\"Polish\":\"pl\",\"Portuguese(Brazil)\":\"pt-br\",\"Portuguese(Portugal)\":\"pt-pt\",\"Punjabi\":\"pa\",\"Queretaro Otomi\":\"otq\",\"Romanian\":\"ro\",\"Russian\":\"ru\",\"Samoan\":\"sm\",\"Serbian(Cyrillic)\":\"sr-Cyrl\",\"Serbian(Latin)\":\"sr-Latn\",\"Slovak\":\"sk\",\"Slovenian\":\"sl\",\"Spanish\":\"es\",\"Swahili\":\"sw\",\"Swedish\":\"sv\",\"Tahitian\":\"ty\",\"Tamil\":\"ta\",\"Telugu\":\"te\",\"Thai\":\"th\",\"Tongan\":\"to\",\"Turkish\":\"tr\",\"Ukrainian\":\"uk\",\"Urdu\":\"ur\",\"Vietnamese\":\"vi\",\"Welsh\":\"cy\",\"Yucatec Maya\":\"yua\"}\n",
        "LANGUAGE_CODES = {v: k for (k, v) in LANGUAGE_CODES.items()}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: This cell needs cleaning - lots of repeated accesses etc. Even datetime.now\n",
        "query = \"SELECT items.id,items.subtopic, items.full_text, items.user, items.userid, items.lang, items.place, items.retweet_count, items.favorite_count, items.entities, items.topics, items.translations, items.key_phrases, items.named_entities, items.sentiment, items.topickey, items.created_at, items.query, items.inserted_to_CosmosDB_ts, items.in_reply_to_status_id, items.in_reply_to_user_id, items.source from items where items.document_type = 'tweet' and items.inserted_to_CosmosDB_ts >= \"  + str(last_inserted_ts) # Need to see which fields we want from cosmos. items.inserted_to_CosmosDB_ts used to be _ts - check the same?\n",
        "lst, lstsearches, lsthashtags, lsthandles, lstmedia, lstKeyPhrases, lstEntities, lstSentiment,  lstTranslations, lstURLs = ([] for i in range(10))\n",
        "lstEntityAnalysis=[]\n",
        "for posts in tweet_container_client.query_items(query,enable_cross_partition_query=True ): # loop over list of json documents from cosmos, and fill in the lists - translations/keyphrases etc. Using lists to build data model\n",
        "  # using conditionals as not every object has all the fields below.\n",
        "  city = ''\n",
        "  country = ''\n",
        "  Language = ''\n",
        "  id_str = posts[\"id\"]\n",
        "  for l in posts['translations']:\n",
        "    lstTranslations.append([id_str, l, posts['translations'][l], _datetime.now()])\n",
        "  for l in posts['named_entities']:\n",
        "    for entity in posts['named_entities'][l]:\n",
        "      if 'country_azuremaps' in entity.keys() and 'country_code_azuremaps' in entity.keys():\n",
        "        lstEntities.append([id_str, entity['category'], entity['subcategory'], entity['text'],  LANGUAGE_CODES.get(l, \"unknown\"), float(entity['confidence_score']),entity[\"country_azuremaps\"],entity[\"country_code_azuremaps\"], _datetime.now() ])\n",
        "      else:\n",
        "        lstEntities.append([id_str, entity['category'], entity['subcategory'], entity['text'],  LANGUAGE_CODES.get(l, \"unknown\"), float(entity['confidence_score']),None,None, _datetime.now() ])\n",
        "  Language = LANGUAGE_CODES.get(posts['lang'], 'Unknown')\n",
        "  if posts['place'] is None:\n",
        "    city = 'NA'\n",
        "    country = 'NA'  \n",
        "  else:\n",
        "      city = posts[\"place\"]['name']\n",
        "      country = posts[\"place\"]['country']\n",
        "  for hashtag in posts['entities']['hashtags']:\n",
        "    lsthashtags.append([id_str, hashtag['text'], _datetime.now()])\n",
        "  for user_mention in posts['entities']['user_mentions']:\n",
        "    lsthandles.append([id_str, user_mention['screen_name'], _datetime.now()])\n",
        "  for urls in posts['entities']['urls']:\n",
        "    lstURLs.append([id_str, urls['url'], urls['expanded_url'], urls['display_url'],  _datetime.now()])\n",
        "  if 'media' in posts['entities']:\n",
        "    for media in posts['entities']['media']:\n",
        "      lstmedia.append([id_str, media['media_url'], _datetime.now()])\n",
        "  if \"sentiment\" in posts.keys():\n",
        "    lstSentiment.append([id_str, posts[\"sentiment\"][\"sentiment\"], posts[\"sentiment\"][\"score\"], _datetime.now()])\n",
        "  adjustedCreatedDateTime = parse(posts[\"created_at\"])+ timedelta(hours=3) \n",
        "  if \"originalid\" in posts.keys():\n",
        "    idforlink=posts[\"originalid\"]\n",
        "  else:\n",
        "    idforlink=id_str\n",
        "  #append tweet\n",
        "  lst.append([id_str, \n",
        "              posts[\"full_text\"],\n",
        "              posts[\"userid\"],\n",
        "\t      posts[\"topickey\"],\n",
        "\t      posts[\"subtopic\"],\n",
        "              city, country,               \n",
        "              posts[\"retweet_count\"], \n",
        "              posts[\"favorite_count\"], Language,  \n",
        "              0,\n",
        "              posts[\"source\"], posts[\"source\"], \n",
        "              '', #factcheckURL, - for al jazeera, don't need\n",
        "              'https://twitter.com/' + posts['user']['screen_name'] + '/status/' +idforlink,\n",
        "              True if 'RT' in posts[\"full_text\"] else False, #retweets\n",
        "              \"\",#posts[\"possible_news\"],\n",
        "              posts[\"in_reply_to_status_id\"] if posts[\"in_reply_to_status_id\"] is not None else -1 ,\n",
        "              posts[\"in_reply_to_user_id\"] if posts[\"in_reply_to_user_id\"] is not None else -1,\n",
        "              adjustedCreatedDateTime,\n",
        "              adjustedCreatedDateTime,\n",
        "              _datetime.fromtimestamp(posts[\"inserted_to_CosmosDB_ts\"]),\n",
        "              posts[\"inserted_to_CosmosDB_ts\"],\n",
        "              _datetime.now(),\n",
        "             ])\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Create Spark Dataframes\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "  StructField(\"text\",StringType(),True),\n",
        "  StructField(\"userid\",StringType(),True),\n",
        "  StructField(\"topic\",StringType(),True),\n",
        "  StructField(\"subtopic\",StringType(),True),\n",
        "  StructField(\"city\",StringType(),True),\n",
        "  StructField(\"country\",StringType(),True),\n",
        "  StructField(\"retweets\",LongType(),False),\n",
        "  StructField(\"likes\",LongType(),True),\n",
        "  StructField(\"lang\",StringType(),True),\n",
        "  StructField(\"worthinessScore\",LongType(),True),\n",
        "  StructField(\"fullSource\",StringType(),True),\n",
        "  StructField(\"Source\",StringType(),True),\n",
        "  StructField(\"factCheckURL\",StringType(),True),\n",
        "  StructField(\"tweetURL\",StringType(),True),\n",
        "  StructField(\"isRetweet\",StringType(),True),\n",
        "  StructField(\"possibleNews\",StringType(),True),\n",
        "  StructField(\"replyToStatus\",LongType(),True),\n",
        "  StructField(\"replyToUser\",LongType(),True),\n",
        "  StructField(\"created_date\",DateType(),True),\n",
        "  StructField(\"created_datetime\",TimestampType(),True),\n",
        "  StructField(\"inserted_to_CosmosDB_datetime\",TimestampType(),True),\n",
        "  StructField(\"inserted_to_CosmosDB_ts\",LongType(),True),\n",
        "  StructField(\"inserted_datetime\", TimestampType(), True)])\n",
        "dftweets = sqlContext.createDataFrame(lst,schema)\n",
        "dftweets.createOrReplaceTempView(\"dftweets\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "StructField(\"hashtags\",StringType(),False),\n",
        "StructField(\"created_datetime\", TimestampType(), False)])\n",
        "dfhashtags = spark.createDataFrame(lsthashtags, schema)\n",
        "dfhashtags.createOrReplaceTempView(\"dfhashtags\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "StructField(\"handles\",StringType(),False),\n",
        "StructField(\"created_datetime\", TimestampType(), False)])\n",
        "dfhandles = spark.createDataFrame(lsthandles,schema)\n",
        "dfhandles.createOrReplaceTempView(\"dfhandles\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "StructField(\"media\",StringType(),False),\n",
        "StructField(\"created_datetime\", TimestampType(), False)])\n",
        "dfmedia = spark.createDataFrame(lstmedia,schema)\n",
        "dfmedia.createOrReplaceTempView(\"dfmedia\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "StructField(\"URL\",StringType(),True),\n",
        "StructField(\"Expanded_URL\",StringType(),True),\n",
        "StructField(\"display_URL\",StringType(),True),\n",
        "StructField(\"created_datetime\", TimestampType(), True)])\n",
        "dfURLs = spark.createDataFrame(lstURLs,schema)\n",
        "dfURLs.createOrReplaceTempView(\"dfURLs\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "StructField(\"Language\",StringType(),False),\n",
        "StructField(\"Text\",StringType(),False),\n",
        "StructField(\"created_datetime\", TimestampType(), True)])\n",
        "dfTranslations = spark.createDataFrame(lstTranslations,schema)\n",
        "dfTranslations.createOrReplaceTempView(\"dfTranslations\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "StructField(\"category\",StringType(),False),\n",
        "StructField(\"subcategory\",StringType(),True),\n",
        "StructField(\"value\",StringType(),True),\n",
        "StructField(\"Language\",StringType(),True),\n",
        "StructField(\"confidence_score\",FloatType(),True),\n",
        "StructField(\"country_azuremaps\",StringType(),True),\n",
        "StructField(\"country_code_azuremaps\",StringType(),True),\n",
        "StructField(\"created_datetime\", TimestampType(), True)])\n",
        "dfEntities = spark.createDataFrame(lstEntities,schema)\n",
        "dfEntities.createOrReplaceTempView(\"dfEntities\")\n",
        "schema = StructType([StructField(\"id\", StringType(), False),\n",
        "StructField(\"sentiment\", StringType(), True),\n",
        "StructField(\"overallscore\", FloatType(), True),\n",
        "StructField(\"created_datetime\", TimestampType(), True)])\n",
        "dfSentiment = spark.createDataFrame(lstSentiment, schema)\n",
        "dfSentiment.createOrReplaceTempView(\"dfSentiment\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if dftweets.count() == 0:\n",
        "  print(\"Didn't capture new tweets.\")\n",
        "else:\n",
        "  print(str(dftweets.count() ) + \" tweets to process.\")\n",
        "# # Synapse Data Ingestion\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dftweets = spark.sqlContext.sql (\"select * from dftweets\")\n",
        "scala_dftweets.write.synapsesql(DB_NAME+\".stg.[Tweets]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {
          "language": "scala"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfhashtags = spark.sqlContext.sql (\"select * from dfhashtags\")\n",
        "scala_dfhashtags.write.synapsesql(DB_NAME+\".stg.[Hashtags]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {
          "language": "scala"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfhandles = spark.sqlContext.sql (\"select * from dfhandles\")\n",
        "scala_dfhandles.write.synapsesql(DB_NAME+\".stg.[Handles]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {
          "language": "scala"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfmedia = spark.sqlContext.sql (\"select * from dfmedia\")\n",
        "scala_dfmedia.write.synapsesql(DB_NAME+\".stg.[TweetMedia]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfSentiment = spark.sqlContext.sql (\"select * from dfSentiment\")\n",
        "scala_dfSentiment.write.synapsesql(DB_NAME+\".stg.[Sentiments]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfURLs = spark.sqlContext.sql (\"select * from dfURLs\")\n",
        "scala_dfURLs.write.synapsesql(DB_NAME+\".stg.[TweetURLs]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfTranslations = spark.sqlContext.sql (\"select * from dfTranslations\")\n",
        "scala_dfTranslations.write.synapsesql(DB_NAME+\".stg.[Translations]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfEntities = spark.sqlContext.sql (\"select * from dfEntities\")\n",
        "scala_dfEntities.write.synapsesql(DB_NAME+\".stg.[TweetsEntities]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "description": "CosmosToSynapse-Tweets",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}