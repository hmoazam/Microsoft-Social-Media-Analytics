{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "query = \"FIFA World Cup Qatar\"\r\n",
        "# https://developer.twitter.com/en/docs/twitter-api/v1/rules-and-filtering/search-operators - query reference\r\n",
        "users = \"\"\r\n",
        "topic = \"FIFA 2022\"\r\n",
        "subtopic = \"\"\r\n",
        "query_language = \"All\"\r\n",
        "target_languages = \"English,Arabic\"\r\n",
        "num_tweets = 100\r\n",
        "days = 7\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "session_starting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4651197Z",
              "session_start_time": "2022-03-19T16:25:32.5011985Z",
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , SessionStarting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": 1,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "tags": [
          "parameters"
        ]
      }
    },
    {
      "cell_type": "code",
      "source": [
        "LANGUAGE_CODES={\"All\":\"\",\"Afrikaans\":\"af\",\"Arabic\":\"ar\",\"Assamese\":\"as\",\"Bangla\":\"bn\",\"Bosnian(Latin)\":\"bs\",\"Bulgarian\":\"bg\",\"Cantonese(Traditional)\":\"yue\",\"Catalan\":\"ca\",\"Chinese Simplified\":\"zh-Hans\",\"Chinese Traditional\":\"zh-Hant\",\"Croatian\":\"hr\",\"Czech\":\"cs\",\"Dari\":\"prs\",\"Danish\":\"da\",\"Dutch\":\"nl\",\"English\":\"en\",\"Estonian\":\"et\",\"Fijian\":\"fj\",\"Filipino\":\"fil\",\"Finnish\":\"fi\",\"French\":\"fr\",\"German\":\"de\",\"Greek\":\"el\",\"Gujarati\":\"gu\",\"Haitian Creole\":\"ht\",\"Hebrew\":\"he\",\"Hindi\":\"hi\",\"Hmong Daw\":\"mww\",\"Hungarian\":\"hu\",\"Icelandic\":\"is\",\"Indonesian\":\"id\",\"Irish\":\"ga\",\"Italian\":\"it\",\"Japanese\":\"ja\",\"Kannada\":\"kn\",\"Kazakh\":\"kk\",\"Klingon\":\"tlh-Latn\",\"Klingon(plqaD)\":\"tlh-Piqd\",\"Korean\":\"ko\",\"Kurdish(Central)\":\"ku\",\"Kurdish(Northern)\":\"kmr\",\"Latvian\":\"lv\",\"Lithuanian\":\"lt\",\"Malagasy\":\"mg\",\"Malay\":\"ms\",\"Malayalam\":\"ml\",\"Maltese\":\"mt\",\"Maori\":\"mi\",\"Marathi\":\"mr\",\"Norwegian\":\"nb\",\"Odia\":\"or\",\"Pashto\":\"ps\",\"Persian\":\"fa\",\"Polish\":\"pl\",\"Portuguese(Brazil)\":\"pt-br\",\"Portuguese(Portugal)\":\"pt-pt\",\"Punjabi\":\"pa\",\"Queretaro Otomi\":\"otq\",\"Romanian\":\"ro\",\"Russian\":\"ru\",\"Samoan\":\"sm\",\"Serbian(Cyrillic)\":\"sr-Cyrl\",\"Serbian(Latin)\":\"sr-Latn\",\"Slovak\":\"sk\",\"Slovenian\":\"sl\",\"Spanish\":\"es\",\"Swahili\":\"sw\",\"Swedish\":\"sv\",\"Tahitian\":\"ty\",\"Tamil\":\"ta\",\"Telugu\":\"te\",\"Thai\":\"th\",\"Tongan\":\"to\",\"Turkish\":\"tr\",\"Ukrainian\":\"uk\",\"Urdu\":\"ur\",\"Vietnamese\":\"vi\",\"Welsh\":\"cy\",\"Yucatec Maya\":\"yua\"}\r\n",
        "topic = topic.lower()\r\n",
        "# username = user\r\n",
        "userslist = users.split(',')\r\n",
        "query_language = LANGUAGE_CODES.get(query_language, \"\")\r\n",
        "target_languages = [LANGUAGE_CODES.get(lang, \"\") for lang in target_languages.split(\",\")]\r\n",
        "if \"en\" not in target_languages:\r\n",
        "  target_languages.append(\"en\") # we always include english in target languages\r\n",
        "num_tweets = int(num_tweets)\r\n",
        "max_days = int(days)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4669732Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "assert (query == \"\") or (users == \"\") # Can either search by query or by user, not both"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4687005Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"config\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4704277Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"common\""
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4727224Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\r\n",
        "import sys\r\n",
        "import copy\r\n",
        "import tweepy\r\n",
        "import urllib.parse\r\n",
        "import sys, time, json, requests, uuid\r\n",
        "\r\n",
        "from tweepy import API\r\n",
        "from tweepy import Cursor\r\n",
        "from tweepy import OAuthHandler\r\n",
        "\r\n",
        "from dateutil.parser import parse\r\n",
        "from datetime import datetime, date, timedelta # don't import time here. It messes with the default library\r\n",
        "\r\n",
        "from azure.cosmos import CosmosClient\r\n",
        "from azure.core.credentials import AzureKeyCredential\r\n",
        "from azure.ai.textanalytics import TextAnalyticsClient"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4784684Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = CosmosClient(COSMOS_URL, {'masterKey': COSMOS_KEY})\r\n",
        "database = client.get_database_client(COSMOS_DATABASE_NAME)\r\n",
        "\r\n",
        "tweet_container_client = database.get_container_client(container=COSMOS_CONTAINER_NAME)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4813632Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "auth = tweepy.OAuthHandler(TWITTER_API_KEY, TWITTER_API_SECRET_KEY)\r\n",
        "auth.set_access_token(TWITTER_ACCESS_TOKEN, TWITTER_ACCESS_TOKEN_SECRET)\r\n",
        "auth_api = API(auth, wait_on_rate_limit=True, wait_on_rate_limit_notify=True)"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4846174Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "regions = [\"Africa\",\"Arabian Gulf\",\"Asia\",\"Central America\",\"Europe\",\"Middle East\",\"North America\",\"Oceania\",\"South America\"]"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4866497Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_emojis(data):\r\n",
        "    emoji = re.compile(\"[\"\r\n",
        "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\r\n",
        "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\r\n",
        "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\r\n",
        "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\r\n",
        "        u\"\\U00002500-\\U00002BEF\"  # chinese char\r\n",
        "        u\"\\U00002702-\\U000027B0\"\r\n",
        "        u\"\\U00002702-\\U000027B0\"\r\n",
        "        u\"\\U000024C2-\\U0001F251\"\r\n",
        "        u\"\\U0001f926-\\U0001f937\"\r\n",
        "        u\"\\U00010000-\\U0010ffff\"\r\n",
        "        u\"\\u2640-\\u2642\" \r\n",
        "        u\"\\u2600-\\u2B55\"\r\n",
        "        u\"\\u200d\"\r\n",
        "        u\"\\u23cf\"\r\n",
        "        u\"\\u23e9\"\r\n",
        "        u\"\\u231a\"\r\n",
        "        u\"\\ufe0f\"  # dingbats\r\n",
        "        u\"\\u3030\"\r\n",
        "        \"]+\", re.UNICODE)\r\n",
        "    return re.sub(emoji, '', data)\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.488889Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\r\n",
        "def build_entry(topic, status, query_search, container, query_language=None, target_languages=[], username=\"\"):\r\n",
        "    tweet = status._json\r\n",
        "    id_str = str(int(tweet[\"id_str\"])+abs(hash(topic)))\r\n",
        "    # Check for tweets which have already been added\r\n",
        "    search_query = 'select * from items where items.id=\"{0}\"'.format(id_str)\r\n",
        "    items = list(container.query_items(search_query,enable_cross_partition_query=True))\r\n",
        "\r\n",
        "    dt2 = datetime.now()\r\n",
        "    ts = int(time.mktime(dt2.timetuple()))\r\n",
        "    at = dt2.strftime(\"%m/%d/%Y, %H:%M:%S %Z\")\r\n",
        "    tweet['inserted_to_CosmosDB_at'] = at\r\n",
        "    tweet['inserted_to_CosmosDB_ts'] = ts\r\n",
        "\r\n",
        "    new_tweet = True\r\n",
        "    if len(items) > 0:\r\n",
        "        # For existing tweets, assuming tweet text the same, so don't re-process\r\n",
        "        # Update only the retweet and favorite counts \r\n",
        "        print(\"Old Tweet\")\r\n",
        "        updatedtweet = items[0]\r\n",
        "        updatedtweet[\"retweet_count\"] = tweet[\"retweet_count\"]\r\n",
        "        updatedtweet[\"favorite_count\"] = tweet[\"favorite_count\"]\r\n",
        "        tweet = updatedtweet\r\n",
        "        user_obj = None # don't need to re-insert the user if already seen before\r\n",
        "        new_tweet = False\r\n",
        "    elif not(tweet[\"full_text\"].lower().startswith(\"rt \")):\r\n",
        "        print(\"New Tweet\")\r\n",
        "        new_tweet = True\r\n",
        "        tweet[\"originalid\"] = tweet[\"id\"]\r\n",
        "        tweet[\"id\"] = str(int(tweet[\"id_str\"])+abs(hash(topic))) # artifically creating our own ID\r\n",
        "        tweet[\"topickey\"] = topic\r\n",
        "        tweet[\"subtopic\"] = subtopic\r\n",
        "        tweet[\"month_year\"] = str(str(parse(tweet[\"created_at\"]).month) + \"_\"+str(parse(tweet[\"created_at\"]).year))\r\n",
        "        tweet[\"replies\"]=[] # check if we want to keep this like this\r\n",
        "        tmp_text = tweet[\"full_text\"].replace('\\n','. ').replace('\\r','.').replace('..','. ').replace(',.','. ').replace(';.','. ').replace('?.','. ').replace('!.','. ').replace(':.','. ').lstrip('.').lstrip(' ')\r\n",
        "        tmp_text = remove_emojis(tmp_text)\r\n",
        "        tweet[\"text\"]= tmp_text\r\n",
        "        tweet[\"document_type\"] = \"tweet\"\r\n",
        "        if query_search:\r\n",
        "            tweet[\"search_type\"]='Topic Search'  \r\n",
        "            tweet[\"query\"] = query\r\n",
        "        else:\r\n",
        "            tweet[\"search_type\"]='User Search'\r\n",
        "            tweet[\"searched_username\"]=username\r\n",
        "        tweet_text = tweet[\"text\"]\r\n",
        "        # get translation\r\n",
        "        if not(query_language):\r\n",
        "            # will depend on language detection from the translator call\r\n",
        "            translations, query_language = get_translation(tweet_text, target_languages)\r\n",
        "        else:\r\n",
        "            translations, _ = get_translation(tweet_text, target_languages)\r\n",
        "        tweet[\"translations\"] = translations\r\n",
        "        # get named entities. Arabic only supports Person, Location and Organization entities, and seems to be poor, so doing NER on English text\r\n",
        "        named_entity_obj = {}\r\n",
        "        if query_language != \"en\":\r\n",
        "            named_entities = get_ner(translations[\"en\"])\r\n",
        "            org_language_entities = []\r\n",
        "            for ent in named_entities:\r\n",
        "                org_language_ent = copy.deepcopy(ent)\r\n",
        "                org_language_ent[\"text\"] = get_translation(ent[\"text\"], query_language)[0][query_language] # replace with original language text\r\n",
        "                org_language_entities.append(org_language_ent)\r\n",
        "            named_entity_obj[query_language] = org_language_entities\r\n",
        "        else:\r\n",
        "            named_entities = get_ner(tweet_text) # list of objects where each object corresponds to an entity\r\n",
        "                 \r\n",
        "        # add location information from azure maps\r\n",
        "        named_entities_with_location = []\r\n",
        "        for ent in named_entities:\r\n",
        "            new_ent = copy.deepcopy(ent)\r\n",
        "            if ent[\"category\"] == \"Location\" and ent[\"subcategory\"] == \"GPE\":\r\n",
        "                ent_text = ent[\"text\"]\r\n",
        "                if ent_text not in regions:\r\n",
        "                    # pass to Azure Maps to get country\r\n",
        "                    r_json = get_maps_response(ent_text)\r\n",
        "                    if r_json: # i.e. got a response\r\n",
        "                        if r_json[\"summary\"][\"numResults\"] > 0:\r\n",
        "                            if \"address\" in r_json['results'][0].keys():\r\n",
        "                                top_match = r_json['results'][0][\"address\"]\r\n",
        "                                if \"country\" in top_match.keys() and \"countryCode\" in top_match.keys() :\r\n",
        "                                    # there is a location detected, so get the country\r\n",
        "                                    country = top_match[\"country\"]\r\n",
        "                                    country_code = top_match[\"countryCode\"]\r\n",
        "                                    new_ent[\"country_azuremaps\"] = country\r\n",
        "                                    new_ent[\"country_code_azuremaps\"] = country_code\r\n",
        "            named_entities_with_location.append(new_ent)\r\n",
        "        named_entity_obj[\"en\"] = named_entities_with_location\r\n",
        "        for language in target_languages:\r\n",
        "            if language != \"en\":\r\n",
        "                tmp_entities = []\r\n",
        "                for ent in named_entities:\r\n",
        "                    tmp_ = copy.deepcopy(ent)\r\n",
        "                    tmp_[\"text\"] = get_translation(ent[\"text\"],language)[0][language]\r\n",
        "                    tmp_entities.append(tmp_)\r\n",
        "                named_entity_obj[language]=tmp_entities\r\n",
        "        tweet[\"named_entities\"] = named_entity_obj\r\n",
        "        # get sentiment. Not supported for arabic, so do on english. No need to translate back\r\n",
        "        if query_language != \"en\":\r\n",
        "            sentiment, sentiment_score = get_sentiment(translations[\"en\"])\r\n",
        "        else:\r\n",
        "            sentiment, sentiment_score = get_sentiment(tweet_text)\r\n",
        "        tweet[\"sentiment\"] = {\"sentiment\": sentiment, \"score\": sentiment_score}\r\n",
        "        user_obj = tweet[\"user\"]\r\n",
        "        user_obj[\"topickey\"] = topic\r\n",
        "        user_obj[\"id\"] = user_obj[\"id_str\"]\r\n",
        "        user_obj[\"document_type\"] = \"user\"\r\n",
        "        user_obj['inserted_to_CosmosDB_at'] = at\r\n",
        "        user_obj['inserted_to_CosmosDB_ts'] = ts\r\n",
        "        user_obj[\"month_year\"] = str(str(parse(user_obj[\"created_at\"]).month) + \"_\"+str(parse(user_obj[\"created_at\"]).year))\r\n",
        "        user_location = tweet[\"user\"][\"location\"]\r\n",
        "        if user_location != \"\" and user_location not in regions:\r\n",
        "            r_json = get_maps_response(user_location)\r\n",
        "            if r_json: # i.e. got a response\r\n",
        "                if r_json[\"summary\"][\"numResults\"] > 0:\r\n",
        "                    # there is a location detected, so get the country\r\n",
        "                    if \"address\" in r_json['results'][0].keys():\r\n",
        "                        top_match = r_json['results'][0][\"address\"]\r\n",
        "                        if \"country\" in top_match.keys() and \"countryCode\" in top_match.keys():\r\n",
        "                            country = top_match[\"country\"]\r\n",
        "                            country_code = top_match[\"countryCode\"]\r\n",
        "                            user_obj[\"country_azuremaps\"] = country\r\n",
        "                            user_obj[\"country_code_azuremaps\"] = country_code\r\n",
        "        tweet[\"userid\"]=user_obj[\"id\"]\r\n",
        "    else:\r\n",
        "        return None, None, False\r\n",
        "    return tweet, user_obj, new_tweet\r\n",
        "def process_tweets(topic=\"\", query=\"\", language=\"en\", maxdays=365, maxtweets_persearch=1, user=\"\", query_search=True, container=None, target_languages=[], username=\"\"):\r\n",
        "    print(\"Working on topic: \" + topic)\r\n",
        "    end_date = datetime.utcnow() - timedelta(days=maxdays)\r\n",
        "    all_tweets = []\r\n",
        "    all_users = []\r\n",
        "    count = 0\r\n",
        "    # Reference: https://docs.tweepy.org/en/stable/api.html#API.search\r\n",
        "    if query_search:\r\n",
        "    # searching based on the query string\r\n",
        "        if language:\r\n",
        "            for status in Cursor(auth_api.search, q=query, lang=language, result='recent', tweet_mode = \"extended\", include_rts='False').items(maxtweets_persearch):\r\n",
        "                count += 1\r\n",
        "                tweet_obj, user_obj, new_tweet = build_entry(topic, status, query_search, container, language, target_languages)\r\n",
        "                print(new_tweet)\r\n",
        "                all_tweets.append(tweet_obj)\r\n",
        "                if new_tweet:\r\n",
        "                    all_users.append(user_obj)\r\n",
        "                if status.created_at < end_date:\r\n",
        "                    break\r\n",
        "            print(\"Found \"+str(count) +\" tweets for query: \"+ query)\r\n",
        "            return all_tweets, all_users\r\n",
        "        else: # search for tweets regardless of tweet language\r\n",
        "            for status in Cursor(auth_api.search, q=query, result='recent', tweet_mode='extended').items(maxtweets_persearch):\r\n",
        "                count += 1\r\n",
        "                tweet_obj, user_obj, new_tweet = build_entry(topic, status, query_search, container, query_language=None, target_languages=target_languages)\r\n",
        "                all_tweets.append(tweet_obj)\r\n",
        "                all_users.append(user_obj)\r\n",
        "                if status.created_at < end_date:\r\n",
        "                    break \r\n",
        "            print(\"Found \"+str(count) +\" tweets for query: \"+ query)\r\n",
        "            return all_tweets, all_users\r\n",
        "    else:\r\n",
        "    # getting tweets by user\r\n",
        "        for status in Cursor(auth_api.user_timeline, id=user, result='recent', tweet_mode = \"extended\").items(maxtweets_persearch): # this actually only returns the last 20 tweets by the user\r\n",
        "            count += 1\r\n",
        "            tweet_obj, user_obj, new_tweet = build_entry(topic, status, query_search, container, query_language=None, target_languages=target_languages, username=username)\r\n",
        "            all_tweets.append(tweet_obj)\r\n",
        "            print(new_tweet)\r\n",
        "            if new_tweet:\r\n",
        "                all_users.append(user_obj) # todo: optimize so not re-inserting the same user\r\n",
        "            if status.created_at < end_date:\r\n",
        "                break\r\n",
        "        print(\"Found \"+str(count) +\" tweets for user: \"+ user)\r\n",
        "        return all_tweets, all_users\r\n"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.4978306Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if users == \"\": # query search\r\n",
        "    all_tweets, all_users = process_tweets(topic, query, query_language, maxdays=max_days, maxtweets_persearch=num_tweets, user=\"\", query_search=True, container=tweet_container_client, target_languages=target_languages)\r\n",
        "    update_cosmos(all_tweets, tweet_container_client) # insert tweets\r\n",
        "    update_cosmos(all_users, tweet_container_client) # insert users\r\n",
        "else: # user search\r\n",
        "    for usr in userslist:\r\n",
        "        all_tweets, all_users = process_tweets(topic, user=usr, maxdays=max_days, maxtweets_persearch=num_tweets, query_search=False, container=tweet_container_client, target_languages=target_languages, username=usr)\r\n",
        "        update_cosmos(all_tweets, tweet_container_client) # insert tweets\r\n",
        "        update_cosmos(all_users, tweet_container_client) # insert users"
      ],
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.livy.statement-meta+json": {
              "spark_pool": null,
              "session_id": null,
              "statement_id": null,
              "state": "waiting",
              "livy_statement_state": null,
              "queued_time": "2022-03-19T16:25:32.5803271Z",
              "session_start_time": null,
              "execution_start_time": null,
              "execution_finish_time": null
            },
            "text/plain": "StatementMeta(, , , Waiting, )"
          },
          "metadata": {}
        }
      ],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "language": "Python",
      "display_name": "Synapse PySpark"
    },
    "language_info": {
      "name": "python"
    },
    "kernel_info": {
      "name": "synapse_pyspark"
    },
    "description": null,
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}