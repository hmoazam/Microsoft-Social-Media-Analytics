{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# # Libraries\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from dateutil.parser import parse\n",
        "from datetime import datetime, timedelta \n",
        "from pyspark.sql.types import StructType, StructField, IntegerType,StringType,DateType, LongType, DecimalType,TimestampType, BooleanType,FloatType\n",
        "from urllib.parse import urlparse\n",
        "from azure.cosmos import CosmosClient\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%run \"config\"\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to Cosmos\n",
        "client = CosmosClient(COSMOS_URL, {'masterKey': COSMOS_KEY})\n",
        "database = client.get_database_client(COSMOS_DATABASE_NAME)\n",
        "tweet_container_client = database.get_container_client(container=COSMOS_ARTICLE_CONTAINER_NAME)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "last_inserted_ts = 0\n",
        "jdbc_url = \"jdbc:sqlserver://\" + SYNAPSE_WORKSPACE_NAME + \".sql.azuresynapse.net:1433;database=\" + DB_NAME + \";encrypt=true;trustServerCertificate=true;hostNameInCertificate=*.sql.azuresynapse.net;loginTimeout=30;\"\n",
        "jdbcDF = spark.read.format(\"jdbc\").option(\"url\", jdbc_url).option(\"query\", \"SELECT MAX(inserted_to_CosmosDB_ts) AS outp FROM dbo.Articles\").option(\"user\", SQL_USERNAME).option(\"password\", SQL_PASSWORD).load()\n",
        "try:\n",
        "    last_inserted_ts = jdbcDF.first()[0]\n",
        "except: \n",
        "    last_inserted_ts = 0\n",
        "if not(last_inserted_ts): # if the table is empty get back None\n",
        "    last_inserted_ts = 0\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "LANGUAGE_CODES={\"All\":\"\",\"Afrikaans\":\"af\",\"Arabic\":\"ar\",\"Assamese\":\"as\",\"Bangla\":\"bn\",\"Bosnian(Latin)\":\"bs\",\"Bulgarian\":\"bg\",\"Cantonese(Traditional)\":\"yue\",\"Catalan\":\"ca\",\"Chinese Simplified\":\"zh-Hans\",\"Chinese Traditional\":\"zh-Hant\",\"Croatian\":\"hr\",\"Czech\":\"cs\",\"Dari\":\"prs\",\"Danish\":\"da\",\"Dutch\":\"nl\",\"English\":\"en\",\"Estonian\":\"et\",\"Fijian\":\"fj\",\"Filipino\":\"fil\",\"Finnish\":\"fi\",\"French\":\"fr\",\"German\":\"de\",\"Greek\":\"el\",\"Gujarati\":\"gu\",\"Haitian Creole\":\"ht\",\"Hebrew\":\"he\",\"Hindi\":\"hi\",\"Hmong Daw\":\"mww\",\"Hungarian\":\"hu\",\"Icelandic\":\"is\",\"Indonesian\":\"id\",\"Irish\":\"ga\",\"Italian\":\"it\",\"Japanese\":\"ja\",\"Kannada\":\"kn\",\"Kazakh\":\"kk\",\"Klingon\":\"tlh-Latn\",\"Klingon(plqaD)\":\"tlh-Piqd\",\"Korean\":\"ko\",\"Kurdish(Central)\":\"ku\",\"Kurdish(Northern)\":\"kmr\",\"Latvian\":\"lv\",\"Lithuanian\":\"lt\",\"Malagasy\":\"mg\",\"Malay\":\"ms\",\"Malayalam\":\"ml\",\"Maltese\":\"mt\",\"Maori\":\"mi\",\"Marathi\":\"mr\",\"Norwegian\":\"nb\",\"Odia\":\"or\",\"Pashto\":\"ps\",\"Persian\":\"fa\",\"Polish\":\"pl\",\"Portuguese(Brazil)\":\"pt-br\",\"Portuguese(Portugal)\":\"pt-pt\",\"Punjabi\":\"pa\",\"Queretaro Otomi\":\"otq\",\"Romanian\":\"ro\",\"Russian\":\"ru\",\"Samoan\":\"sm\",\"Serbian(Cyrillic)\":\"sr-Cyrl\",\"Serbian(Latin)\":\"sr-Latn\",\"Slovak\":\"sk\",\"Slovenian\":\"sl\",\"Spanish\":\"es\",\"Swahili\":\"sw\",\"Swedish\":\"sv\",\"Tahitian\":\"ty\",\"Tamil\":\"ta\",\"Telugu\":\"te\",\"Thai\":\"th\",\"Tongan\":\"to\",\"Turkish\":\"tr\",\"Ukrainian\":\"uk\",\"Urdu\":\"ur\",\"Vietnamese\":\"vi\",\"Welsh\":\"cy\",\"Yucatec Maya\":\"yua\"}\n",
        "LANGUAGE_CODES = {v: k for (k, v) in LANGUAGE_CODES.items()}\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"SELECT * from items where items.document_type = 'news_article' and items._ts > \"  + str(last_inserted_ts)\n",
        "lstNewsArticles, lstEntities,lstKeyPhrases, lstSentiment, lstTranslations  = ([] for i in range(5))\n",
        "for article in tweet_container_client.query_items(query,enable_cross_partition_query=True ):\n",
        "  domain = urlparse(article[\"url\"]).netloc\n",
        "  publishedAt = parse(article['publishedAt']) + timedelta(hours=3) \n",
        "  inserted_to_CosmosDB_datetime = datetime.fromtimestamp(article['_ts'])\n",
        "  inserted_to_CosmosDB_ts = int(article['_ts'])\n",
        "  title=article['title']\n",
        "  description=article['description']\n",
        "  content = article['content']\n",
        "  lstNewsArticles.append([article['id'], article['topickey'], article['subtopic'],article['source']['name'], article['author'],title, description , article['url'], article['urlToImage'], content, publishedAt, inserted_to_CosmosDB_datetime, inserted_to_CosmosDB_ts,domain, article['lang'], 'News Article'])\n",
        "  title_translated = article[\"translations_title\"]\n",
        "  description_translated = article[\"translations_description\"]\n",
        "  content_translated = article[\"translations_content\"]\n",
        "  id_ = article[\"id\"]\n",
        "  langs = title_translated.keys()\n",
        "  for lang in langs: \n",
        "    title_ = title_translated[lang]\n",
        "    desc_ = description_translated[lang]\n",
        "    content_ = content_translated[lang]\n",
        "    lstTranslations.append([id_, lang, title_, desc_, content_, datetime.now()])\n",
        "  for l in article['named_entities']:\n",
        "    for entity in article['named_entities'][l]:\n",
        "      lstEntities.append([article['id'], entity['category'], entity['subcategory'], entity['text'], LANGUAGE_CODES.get(l, \"unknown\"), float(entity['confidence_score']), datetime.now() ])\n",
        "  if \"sentiment\" in article.keys():\n",
        "    lstSentiment.append([article['id'], article[\"sentiment\"][\"sentiment\"], article[\"sentiment\"][\"score\"], datetime.now()])  \n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "  StructField(\"Language\",StringType(),False),   \n",
        "  StructField(\"Title\",StringType(),True),   \n",
        "  StructField(\"Description\",StringType(),True),   \n",
        "  StructField(\"Content\",StringType(),True),   \n",
        "  StructField(\"created_datetime\", TimestampType(), True)])\n",
        "dfTranslations = spark.createDataFrame(lstTranslations,schema)\n",
        "dfTranslations.createOrReplaceTempView(\"dfTranslations\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "  StructField(\"KeyPhrase\",StringType(),False),\n",
        "  StructField(\"Language\",StringType(),True),\n",
        "  StructField(\"created_datetime\", TimestampType(), True)])\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "  StructField(\"category\",StringType(),False),\n",
        "  StructField(\"subcategory\",StringType(),True),\n",
        "  StructField(\"value\",StringType(),True),\n",
        "  StructField(\"Language\",StringType(),True),\n",
        "  StructField(\"confidence_score\",FloatType(),True),\n",
        "  StructField(\"created_datetime\", TimestampType(), True)])\n",
        "dfEntities = spark.createDataFrame(lstEntities,schema)\n",
        "dfEntities.createOrReplaceTempView(\"dfEntities\")\n",
        "schema = StructType([StructField(\"id\", StringType(), False),\n",
        "  StructField(\"sentiment\", StringType(), True),\n",
        "  StructField(\"overallscore\", FloatType(), True),\n",
        "  StructField(\"created_datetime\", TimestampType(), True)])\n",
        "dfSentiment = spark.createDataFrame(lstSentiment, schema)\n",
        "dfSentiment.createOrReplaceTempView(\"dfSentiment\")\n",
        "schema = StructType([StructField(\"id\",StringType(),False),\n",
        "  StructField(\"topic\",StringType(),True),\n",
        "  StructField(\"subtopic\",StringType(),True),\n",
        "  StructField(\"sourceName\",StringType(),True),\n",
        "  StructField(\"author\",StringType(),True),\n",
        "  StructField(\"title\", StringType(), True),\n",
        "  StructField(\"description\", StringType(), True),\n",
        "  StructField(\"url\", StringType(), True),\n",
        "  StructField(\"urlToImage\",StringType(),True),\n",
        "  StructField(\"content\",StringType(),True),\n",
        "  StructField(\"publishedAt\", TimestampType(), True),\n",
        "  StructField(\"inserted_to_CosmosDB_datetime\",TimestampType(),True),\n",
        "  StructField(\"inserted_to_CosmosDB_ts\", LongType(), True),\n",
        "  StructField(\"domainname\", StringType(), True),\n",
        "  StructField(\"language\", StringType(), True),\n",
        "  StructField(\"Type\", StringType(), True)])\n",
        "dfNewsArticles = spark.createDataFrame(lstNewsArticles, schema)\n",
        "dfNewsArticles.createOrReplaceTempView(\"dfNewsArticles\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "if dfNewsArticles.count() == 0 :\n",
        "  print(\"Didn't capture news articles.\")\n",
        "  #dbutils.notebook.exit(0)\n",
        "else:\n",
        "  print(str(dfNewsArticles.count()) + \" news articles to process.\")\n",
        "# # Synapse Data Ingestion\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfNewsArticles = spark.sqlContext.sql (\"select * from dfNewsArticles\")\n",
        "scala_dfNewsArticles.write.synapsesql(DB_NAME+\".stg.[Articles]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {
          "language": "scala"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfEntities = spark.sqlContext.sql (\"select * from dfEntities\")\n",
        "scala_dfEntities.write.synapsesql(DB_NAME+\".stg.[ArticlesEntities]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {
          "language": "scala"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfSentiment = spark.sqlContext.sql (\"select * from dfSentiment\")\n",
        "scala_dfSentiment.write.synapsesql(DB_NAME+\".stg.[ArticlesSentiments]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {
          "language": "scala"
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%spark\n",
        "val scala_dfTranslations = spark.sqlContext.sql (\"select * from dfTranslations\")\n",
        "scala_dfTranslations.write.synapsesql(DB_NAME+\".stg.[ArticlesTranslations]\", Constants.INTERNAL)\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "microsoft": {
          "language": "scala"
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "synapse_pyspark",
      "display_name": "python"
    },
    "language_info": {
      "name": "python"
    },
    "description": "CosmosToSynapse-NewsArticles",
    "save_output": true,
    "synapse_widget": {
      "version": "0.1",
      "state": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}